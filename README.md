# ğŸ’¼ Credit Default Prediction & ECL Modeling

## ğŸ“Œ Project Objective

This project aims to build a robust and interpretable machine learning pipeline to predict the **Probability of Default (PD)** and calculate the **Expected Credit Loss (ECL)** for loan applicants. It follows a simplified **IFRS 9 framework** using publicly available data.

> ğŸ’¡ **ECL Formula**:  
**ECL = PD Ã— LGD Ã— EAD**

Where:
- **PD** â€” Probability of Default (learned via ML)
- **LGD** â€” Loss Given Default (assumed as 0.45)
- **EAD** â€” Exposure at Default (estimated as `debt_ratio Ã— monthly_income`)

---

## ğŸ“‚ Dataset

- Source: [Kaggle â€” Give Me Some Credit](https://www.kaggle.com/c/GiveMeSomeCredit)
- Rows: 150,000
- Target: `SeriousDlqin2yrs` â€” binary indicator of default within 2 years
- No real LGD or EAD columns â†’ assumptions were made for ECL estimation

---

## ğŸ› ï¸ Technologies Used

- **Python 3.x**
- `pandas`, `numpy`, `matplotlib`, `seaborn`
- `scikit-learn` (pipelines, preprocessing, GridSearchCV)
- `lightgbm` for gradient boosting
- `shap` for explainability

---

## ğŸ§ª Workflow Overview

### 1. **Data Cleaning**
- Removed duplicates
- Clipped extreme outliers
- Filled missing values:
  - `monthly_income` â†’ median
  - `dependents` â†’ 0
- Clipped values like `past_due_*` to max 10 (e.g., coded 98 = 98+ days)

### 2. **Model Training**
Trained 3 models using full pipeline and `GridSearchCV`:

| Model                | CV ROC-AUC | Validation ROC-AUC |
|---------------------|------------|---------------------|
| Logistic Regression | 0.8557     | 0.8554              |
| Random Forest       | 0.8644     | 0.8629              |
| âœ… LightGBM (Best)   | 0.8655     | 0.8644              |

> All models included consistent preprocessing: imputation, scaling, clipping, and class balancing.

### 3. **Model Explainability**
- Used **SHAP** to analyze the impact of each feature
- Top features:
  - `revolving_utilization` (credit usage)
  - `past_due_*` variables (delinquencies)
  - `age` (younger â†’ more risky)
- Weak features:
  - `dependents`, `real_estate_loans` (flat SHAP)

### 4. **ECL Estimation**
- Set **LGD = 0.45** (industry proxy)
- Estimated **EAD = debt_ratio Ã— monthly_income**
- Calculated ECL for both train and test datasets
- Exported test results as: `ECL_results.csv`

### 5. **ECL Insights**
- Most clients have low ECL â†’ healthy portfolio
- Small segment of clients contributes to large portion of credit risk
- Top 10 clients with highest ECL identified for risk-based actions

---

## ğŸ“Š Key Visuals

- ROC Curve and AUC scores
- SHAP Summary and Dependence Plots
- Distribution of ECL across the portfolio
- Table of top clients by ECL

---

## ğŸ“ Conclusion

âœ… We built a production-ready pipeline to calculate ECL using public data.  
âš™ï¸ All data processing and modeling is done within scikit-learn pipelines.  
ğŸ“ˆ Model performance is strong and interpretable (LightGBM ROC-AUC â‰ˆ 0.864).  
ğŸ“¦ Final predictions (PD, LGD, EAD, ECL) saved to `ECL_results.csv`.

> ğŸ“ The project is ready to be extended to real-world systems with actual LGD/EAD inputs or connected to internal credit databases.

---

## ğŸ“ Files in Repository

- `give_me_some_credit_v5.ipynb` â€” full notebook with code, results, and visuals
- `ECL_results.csv` â€” final table of predictions for test data
- `README.md` â€” project overview
